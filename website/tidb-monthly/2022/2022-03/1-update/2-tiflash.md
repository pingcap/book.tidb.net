---
title: TiFlash 开源了
hide_title: true
---

# TiFlash 开源了

![0.jpeg](https://img1.www.pingcap.com/prod/0_0d85512f2d.jpeg)

TiFlash 终于 [开源 ](https://github.com/pingcap/tiflash)了，而且不再闭源：**我们选了这个特别的节日开源并做出承诺，希望能显得更加真诚 :)**

PingCAP 一直以来对开源这件事情，是有**信仰**的。这种信仰植根于创始人的情怀，也深深影响了这个旗帜下汇聚的所有人。开源本身并不是一种市场策略：远在我们看清开源到底能带来什么的时候，我们就有了开源的坚持，这也使得我们的开源精神相对**纯粹**。作为 TiDB 社区的一个重要力量，我们和其他社区贡献者一起贡献代码，通过社区用户的使用、打磨，大家共同分享 TiDB 不断进步的红利，没有任何人为障碍和边界。自由和共赢的理念，也是我们对技术对开源的**倔强**。

![01.png](https://img1.www.pingcap.com/prod/01_39623260e8.png)

**TiDB 是一款 HTAP 分布式数据库，其中提供 HTAP 能力的重要组成部分是 TiFlash**。从原型开发起，由于是一个探索型的项目，一开始我们并没有想好最终形态和架构（TiFlash 在 2018 年也的确经历了一次彻底翻新重做），为了不引起外界太多讨论，我们选择了让 TiFlash 暂时闭源，等大体成型了再开源。虽然从一开始我们就计划开源，但待到真正着手做的时候，我们发现它已经欠下了不少「开源债」，显得和 TiDB 主干格格不入：发布流程没有完全融合，开源所需的文档缺失，编译体验相当糟糕，甚至部分代码风格有些丑陋。要还上这些债务，需要投入相当多的时间和人力。与此同时，产品迭代的压力和有限的资源就成为约束 TiFlash 开源的最大障碍。

作为将开源当成信仰的团队而言，TiFlash 闭源对我们来说其实是如鲠在喉。因此，虽然仍有诸多缺失，我们选择投入时间逐步还债。毕竟，单独就这个引擎而言，我们也从社区有所取，**无论是 ClickHouse 绝佳的 Runtime 基础，还是诸多社区用户提供的真实场景和改进建议，这些都让 TiFlash 获益无算，可以说没有这些助力，就不会有 TiFlash**。

TiFlash 首先受益于开源社区的其他项目，除开我们所使用的各类基础库，最重要的部分是：TiFlash 的框架代码是基于 ClickHouse 的。**我们使用 ClickHouse 的方式是将它当做一个单机的 Compute Runtime 和 Server 框架，并复用了 Storage Interface**。针对在线事务数据分析的大目标，我们加入了事务相关逻辑、MPP 能力和可实时更新的列存引擎，引入 Raft 协议和 MySQL 兼容以融入整个 TiDB 体系。很感谢 ClickHouse 为社区提供了一套高性能的计算引擎，对我们而言，一个好的基础大大加速了 TiFlash 的研发进度。**值得一提的是，TiFlash 和 ClickHouse 拥有完全不同的擅长场景：TiFlash 完全偏重于事务性数据的分析，我们也并不希望用户以为 TiFlash 是更好的 ClickHouse**。

作为一个年轻的引擎，在两年多的时间里，受到天使用户们包容和帮助的同时，我们也通过近距离倾听用户的声音高速迭代改进产品。这一切也反过来帮助用户简化了分析链路的架构，享受实时数据的红利。彼时 TiFlash 虽未开源，却已得到了 TiDB 社区的加持。

我们清楚地记得，在早期版本时，税务系统的朋友和我们一起测试，尝试优化缴税流程的实时性，虽未成功落地，但让我们对系统设计在真实场景上的得失有了第一手体感，进而直接导致了一次重大重构：我们完全重新设计了存储层，引入了 Raft Learner 作为复制协议，且决定使用 TiDB-Server 作为统一入口而非 TiSpark，这也是大家今日所见的架构；而随着 TiDB 4.0 一起发布的正式版本，则可以说是完全仰赖小红书在发布前数月就提供场景和我们一起探索，而这个尝试最终成功落地电商实时看板场景，让交易数据得以实时展现；待到 5.0，从中通有惊无险却时有毛刺的 618，到流量倍增却平平稳稳的双十一，TiFlash 在高压实时场景的表现得到了提升和验证。而这代表的不仅是全球领先快递公司的核心业务落地，也不仅是数万 TPS 和数十亿订单的实时监控，更是用户的包容，信任和互助。

![02.jpeg](https://img1.www.pingcap.com/prod/02_8af891c036.jpeg)

**TiFlash 在中通快递**

至今我们都经常会收到客户的私信，说自己某个场景由于 TiFlash 的能力而得到实在的业务收益。每次看到这些可爱的消息，我们都会在团队内分享喜悦。能帮助大家，提供独特的价值，是我们所追求的；与此同时，社区的支持，也是产品发展不可或缺的给养，推动它在更严苛更有价值的场景落地。可以说，没有社区的力量，我们也无法向更多人提供更好的产品。而时至今日，开源则是一个全新的渠道，让 TiFlash 能以更深入的方式和社区互助共赢。

最后容我们说一句抱歉。虽然开源，但 TiFlash 仍然缺失必要的面向社区的代码解读。关于 TiFlash 和 TiDB HTAP 的架构解析，可以参考我们在 VLDB 2020 发布的论文《 [TiDB: A Raft-based HTAP Database ](http://www.vldb.org/pvldb/vol13/p3072-huang.pdf)》，或者《 [TiDB HTAP 深度解读 ](https://zhuanlan.zhihu.com/p/205663113)》、《 [TiDB 的列式存储引擎是如何实现的？ ](https://pingcap.com/zh/blog/how-tidb-implements-columnar-storage-engine)》文章。社区同学也整理了一份 TiFlash 相关文章的 [合辑列表 ](https://asktug.com/t/topic/632816)。可惜的是，这些都是基于 TiDB 4.0 版本，当时 TiFlash 仍不具备重要的 MPP 能力。除此之外，源码解析和阅读指南，也仍在缺失状态。这些都将在后续的几个月内陆续补上，以帮助大家阅读和理解 TiFlash。希望关注 TiFlash 的大家在使用以外，借助开源能有更多手段帮助它变得更好，无论是更多的函数，算子支持，更直观的 Tracing 能力，还是更快更稳定的 Delta Tree 列存引擎。

是的，我们期待你的贡献，因为这份力量将会借助社区的翅膀飞跃令人惊叹的奇景。

访问 [GitHub TiFlash ](https://github.com/pingcap/tiflash)仓库，开启你的数据实时分析之旅！
